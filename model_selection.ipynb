{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gc # gc ---垃圾回收器接口\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "import lightgbm as lgb\r\n",
    "import xgboost as xgb\r\n",
    "#!pip install catboost\r\n",
    "import catboost as cat\r\n",
    "\r\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Feature Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LOCAL_QUICK = True\r\n",
    "LOCAL_QUICK = False\r\n",
    "\r\n",
    "sample_persent = 0.1\r\n",
    "\r\n",
    "MORE_FE = False\r\n",
    "MORE_FE = True\r\n",
    "\r\n",
    "FE_V1 = False if MORE_FE else True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get data\r\n",
    "if not LOCAL_QUICK:\r\n",
    "    if FE_V1:\r\n",
    "        train_data = pd.read_csv('train_data.csv')\r\n",
    "        test_data = pd.read_csv('test_data.csv')\r\n",
    "    if MORE_FE:\r\n",
    "        train_data = pd.read_csv('train_data_moreFE.csv')\r\n",
    "        test_data = pd.read_csv('test_data_moreFE.csv')  \r\n",
    "\r\n",
    "# FeatureSelect_QUICK = True # Feature Select\r\n",
    "FeatureSelect_QUICK = False \r\n",
    "if FeatureSelect_QUICK: # 使用部分样本进行快速特征选择\r\n",
    "    train_data = train_data.sample(int(len(train_data) * sample_percent))\r\n",
    "\r\n",
    "# train_data = train_data[train_col]\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "\r\n",
    "del train_data\r\n",
    "\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2, random_state=42) # test_size=.3\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGB Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get data\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "del train_data\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2, random_state=42) # test_size=.3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "def xgb_train(X_train, y_train, X_valid, y_valid, verbose=True):\r\n",
    "    model_xgb = xgb.XGBClassifier(\r\n",
    "        max_depth=10, # raw8\r\n",
    "        n_estimators=1000,\r\n",
    "        min_child_weight=300, \r\n",
    "        colsample_bytree=0.8, \r\n",
    "        subsample=0.8, \r\n",
    "        eta=0.3,    \r\n",
    "        seed=42        \r\n",
    "    )\r\n",
    "\r\n",
    "    model_xgb.fit(\r\n",
    "        X_train, \r\n",
    "        y_train,\r\n",
    "        eval_metric='auc',\r\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\r\n",
    "        verbose=verbose,\r\n",
    "        early_stopping_rounds=10 # 早停法，如果auc在10epoch没有进步就stop\r\n",
    "    )\r\n",
    "    print(model_xgb.best_score)\r\n",
    "    return model_xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_xgb = xgb_train(X_train, y_train, X_valid, y_valid, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "prob = model_xgb.predict_proba(test_data)\r\n",
    "\r\n",
    "submission['prob'] = pd.Series(prob[:,1])\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_xgb.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "LGB Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "############DEF:lgb_train################\r\n",
    "def lgb_train(X_train, y_train, X_valid, y_valid, verbose=True):\r\n",
    "    model_lgb = lgb.LGBMClassifier(\r\n",
    "        max_depth=10, # 8\r\n",
    "        n_estimators=1000,\r\n",
    "        min_child_weight=200, \r\n",
    "        colsample_bytree=0.8, \r\n",
    "        subsample=0.8, \r\n",
    "        eta=0.3,    \r\n",
    "        seed=42        \r\n",
    "    )\r\n",
    "\r\n",
    "    model_lgb.fit(\r\n",
    "        X_train, \r\n",
    "        y_train,\r\n",
    "        eval_metric='auc',\r\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\r\n",
    "        verbose=verbose,\r\n",
    "        early_stopping_rounds=10\r\n",
    "    )\r\n",
    "\r\n",
    "    print(model_lgb.best_score_['valid_1']['auc'])\r\n",
    "    return model_lgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_lgb = lgb_train(X_train, y_train, X_valid, y_valid, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "prob = model_lgb.predict_proba(test_data)\r\n",
    "submission['prob'] = pd.Series(prob[:,1])\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_lgb.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CAT Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cat_train(X_train, y_train, X_valid, y_valid, verbose=True):\r\n",
    "    model_cat = cat.CatBoostClassifier(learning_rate=0.02, iterations=5000, eval_metric='AUC', od_wait=50,\r\n",
    "                                od_type='Iter', random_state=10, thread_count=8, l2_leaf_reg=1, verbose=verbose)\r\n",
    "    model_cat.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50,\r\n",
    "            use_best_model=True)\r\n",
    "\r\n",
    "    print(model_cat.best_score_['validation']['AUC'])\r\n",
    "    return model_cat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_cat = cat_train(X_train, y_train, X_valid, y_valid, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "prob = model_cat.predict_proba(test_data)\r\n",
    "submission['prob'] = pd.Series(prob[:,1])\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_cat.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "StratifiedKFold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 构造训练集和测试集\r\n",
    "def get_train_testDF(train_df,label_df):\r\n",
    "    skv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\r\n",
    "    trainX = []\r\n",
    "    trainY = []\r\n",
    "    testX = []\r\n",
    "    testY = []\r\n",
    "    for train_index, test_index in skv.split(X=train_df, y=label_df):\r\n",
    "        train_x, train_y, test_x, test_y = train_df.iloc[train_index, :], label_df.iloc[train_index], \\\r\n",
    "                                            train_df.iloc[test_index, :], label_df.iloc[test_index]\r\n",
    "\r\n",
    "        trainX.append(train_x)\r\n",
    "        trainY.append(train_y)\r\n",
    "        testX.append(test_x)\r\n",
    "        testY.append(test_y)\r\n",
    "    return trainX, testX, trainY, testY"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "lightgbm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get data\r\n",
    "if not LOCAL_QUICK:\r\n",
    "    if FE_V1:\r\n",
    "        train_data = pd.read_csv('train_data.csv')\r\n",
    "        test_data = pd.read_csv('test_data.csv')\r\n",
    "    if MORE_FE:\r\n",
    "        train_data = pd.read_csv('train_data_moreFE.csv')\r\n",
    "        test_data = pd.read_csv('test_data_moreFE.csv')  \r\n",
    "\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "\r\n",
    "del train_data\r\n",
    "\r\n",
    "# Split Train&Valid Data\r\n",
    "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\r\n",
    "# lightgbm模型\r\n",
    "\r\n",
    "pred_lgbms = []\r\n",
    "for i in range(5):\r\n",
    "    print('\\n============================LGB training use Data {}/5============================\\n'.format(i+1))\r\n",
    "    model_lgb = lgb.LGBMClassifier(\r\n",
    "        max_depth=10, # 8\r\n",
    "        n_estimators=1000,\r\n",
    "        min_child_weight=200, \r\n",
    "        colsample_bytree=0.8, \r\n",
    "        subsample=0.8, \r\n",
    "        eta=0.3,    \r\n",
    "        seed=42\r\n",
    "    )\r\n",
    "\r\n",
    "    model_lgb.fit(\r\n",
    "        X_train[i], \r\n",
    "        y_train[i],\r\n",
    "        eval_metric='auc',\r\n",
    "        eval_set=[(X_train[i], y_train[i]), (X_valid[i], y_valid[i])],\r\n",
    "        verbose=False,\r\n",
    "        early_stopping_rounds=10\r\n",
    "    )\r\n",
    "\r\n",
    "    print(model_lgb.best_score_['valid_1']['auc'])\r\n",
    "\r\n",
    "    pred = model_lgb.predict_proba(test_data)\r\n",
    "    pred = pd.DataFrame(pred[:,1])\r\n",
    "    pred_lgbms.append(pred)\r\n",
    "pred_lgbms = pd.concat(pred_lgbms, axis=1)\r\n",
    "print(pred_lgbms)\r\n",
    "\r\n",
    "submission['prob'] = pred_lgbms.mean(axis=1)\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_KFold_lgb.csv', index=False)\r\n",
    "\r\n",
    "####0.6784"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "catgbm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# get data\r\n",
    "if not LOCAL_QUICK:\r\n",
    "    if FE_V1:\r\n",
    "        train_data = pd.read_csv('train_data.csv')\r\n",
    "        test_data = pd.read_csv('test_data.csv')\r\n",
    "    if MORE_FE:\r\n",
    "        train_data = pd.read_csv('train_data_moreFE.csv')\r\n",
    "        test_data = pd.read_csv('test_data_moreFE.csv')  \r\n",
    "\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "\r\n",
    "del train_data\r\n",
    "\r\n",
    "# Split Train&Valid Data\r\n",
    "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\r\n",
    "# catgbm模型\r\n",
    "\r\n",
    "pred_cats = []\r\n",
    "for i in range(5):\r\n",
    "    print('\\n============================CAT training use Data {}/5============================\\n'.format(i+1))\r\n",
    "    model_cat = cat.CatBoostClassifier(learning_rate=0.02, iterations=5000, eval_metric='AUC', od_wait=50,\r\n",
    "                                od_type='Iter', random_state=10, thread_count=8, l2_leaf_reg=1, verbose=False)\r\n",
    "    model_cat.fit(X_train[i], y_train[i], eval_set=[(X_valid[i], y_valid[i])], early_stopping_rounds=50,\r\n",
    "            use_best_model=True)\r\n",
    "    # print(model_cat.evals_result_)\r\n",
    "    print(model_cat.best_score_['validation']['AUC'])\r\n",
    "\r\n",
    "    pred = model_cat.predict_proba(test_data)\r\n",
    "    pred = pd.DataFrame(pred[:,1])\r\n",
    "    pred_cats.append(pred)\r\n",
    "pred_cats = pd.concat(pred_cats, axis=1)\r\n",
    "\r\n",
    "submission['prob'] = pred_cats.mean(axis=1)\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_KFold_cat.csv', index=False)\r\n",
    "\r\n",
    "\r\n",
    "#### 0.68001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "xgboost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get data\r\n",
    "if not LOCAL_QUICK:\r\n",
    "    if FE_V1:\r\n",
    "        train_data = pd.read_csv('train_data.csv')\r\n",
    "        test_data = pd.read_csv('test_data.csv')\r\n",
    "    if MORE_FE:\r\n",
    "        train_data = pd.read_csv('train_data_moreFE.csv')\r\n",
    "        test_data = pd.read_csv('test_data_moreFE.csv')  \r\n",
    "\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "\r\n",
    "del train_data\r\n",
    "\r\n",
    "# Split Train&Valid Data\r\n",
    "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\r\n",
    "# xgboost模型\r\n",
    "\r\n",
    "pred_xgbs = []\r\n",
    "for i in range(5):\r\n",
    "    print('\\n============================XGB training use Data {}/5============================\\n'.format(i+1))\r\n",
    "    model_xgb = xgb.XGBClassifier(\r\n",
    "        max_depth=10, # raw8\r\n",
    "        n_estimators=1000,\r\n",
    "        min_child_weight=300, \r\n",
    "        colsample_bytree=0.8, \r\n",
    "        subsample=0.8, \r\n",
    "        eta=0.3,    \r\n",
    "        seed=42        \r\n",
    "    )\r\n",
    "\r\n",
    "    model_xgb.fit(\r\n",
    "        X_train[i], \r\n",
    "        y_train[i],\r\n",
    "        eval_metric='auc',\r\n",
    "        eval_set=[(X_train[i], y_train[i]), (X_valid[i], y_valid[i])],\r\n",
    "        verbose=False,\r\n",
    "        early_stopping_rounds=10 # 早停法，如果auc在10epoch没有进步就stop\r\n",
    "    )    \r\n",
    "\r\n",
    "    print(model_xgb.best_score)\r\n",
    "\r\n",
    "    pred = model_xgb.predict_proba(test_data)\r\n",
    "    pred = pd.DataFrame(pred[:,1])\r\n",
    "    pred_xgbs.append(pred)\r\n",
    "pred_xgbs = pd.concat(pred_xgbs, axis=1)\r\n",
    "\r\n",
    "# make submission\r\n",
    "submission['prob'] = pred_xgbs.mean(axis=1)\r\n",
    "# submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('submission_KFold_xgb.csv', index=False)\r\n",
    "\r\n",
    "#### 0.6803"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}